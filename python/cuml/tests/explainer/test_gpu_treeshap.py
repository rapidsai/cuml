#
# Copyright (c) 2021-2022, NVIDIA CORPORATION.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import json
import pytest
import treelite
import numpy as np
import pandas as pd
import cupy as cp
import cudf
from hypothesis import given, settings, assume, HealthCheck, strategies as st
from cuml.explainer.tree_shap import TreeExplainer
from cuml.internals.import_utils import has_lightgbm, has_shap
from cuml.internals.import_utils import has_sklearn
from cuml.common.exceptions import NotFittedError
from cuml.ensemble import RandomForestRegressor as curfr
from cuml.ensemble import RandomForestClassifier as curfc
import cuml
from cuml.testing.utils import as_type

pytestmark = pytest.mark.skip

# See issue #4729
# Xgboost disabled due to CI failures
xgb = None


def has_xgboost():
    return False


if has_lightgbm():
    import lightgbm as lgb
if has_shap():
    import shap
if has_sklearn():
    from sklearn.datasets import make_regression, make_classification
    from sklearn.ensemble import RandomForestRegressor as sklrfr
    from sklearn.ensemble import RandomForestClassifier as sklrfc


def make_classification_with_categorical(
        *, n_samples, n_features, n_categorical, n_informative, n_redundant,
        n_repeated, n_classes, random_state, numeric_dtype=np.float32):
    X, y = make_classification(
        n_samples=n_samples, n_features=n_features,
        n_informative=n_informative, n_redundant=n_redundant,
        n_repeated=n_repeated, n_classes=n_classes, random_state=random_state,
        n_clusters_per_class=min(2, n_features))
    X, y = X.astype(numeric_dtype), y.astype(numeric_dtype)

    # Turn some columns into categorical, by taking quartiles
    n = np.atleast_1d(y).shape[0]
    X = pd.DataFrame({f'f{i}': X[:, i] for i in range(n_features)})
    for i in range(n_categorical):
        column = f'f{i}'
        n_bins = min(4, n)
        X[column] = pd.qcut(X[column], n_bins, labels=range(n_bins))
    # make sure each target exists
    y[0:n_classes] = range(n_classes)

    assert len(np.unique(y)) == n_classes
    return X, y


def make_regression_with_categorical(
        *, n_samples, n_features, n_categorical, n_informative, random_state,
        numeric_dtype=np.float32, n_targets=1):
    X, y = make_regression(n_samples=n_samples, n_features=n_features,
                           n_informative=n_informative, n_targets=n_targets,
                           random_state=random_state)
    X, y = X.astype(numeric_dtype), y.astype(numeric_dtype)

    # Turn some columns into categorical, by taking quartiles
    n = np.atleast_1d(y).shape[0]
    X = pd.DataFrame({f'f{i}': X[:, i] for i in range(n_features)})
    for i in range(n_categorical):
        column = f'f{i}'
        n_bins = min(4, n)
        X[column] = pd.qcut(X[column], n_bins, labels=range(n_bins))
    return X, y


def count_categorical_split(tl_model):
    model_dump = json.loads(tl_model.dump_as_json(pretty_print=False))
    count = 0
    for tree in model_dump["trees"]:
        for node in tree["nodes"]:
            if "split_type" in node and node["split_type"] == "categorical":
                count += 1
    return count


@pytest.mark.parametrize('objective', ['reg:linear', 'reg:squarederror',
                                       'reg:squaredlogerror',
                                       'reg:pseudohubererror'])
@pytest.mark.skipif(not has_xgboost(), reason="need to install xgboost")
@pytest.mark.skipif(not has_shap(), reason="need to install shap")
@pytest.mark.skipif(not has_sklearn(), reason="need to install scikit-learn")
def test_xgb_regressor(objective):
    n_samples = 100
    X, y = make_regression(n_samples=n_samples, n_features=8, n_informative=8,
                           n_targets=1, random_state=2021)
    # Ensure that the label exceeds -1
    y += (-0.5) - np.min(y)
    assert np.all(y > -1)
    X, y = X.astype(np.float32), y.astype(np.float32)
    dtrain = xgb.DMatrix(X, label=y)
    params = {'objective': objective, 'base_score': 0.5, 'seed': 0,
              'max_depth': 6, 'tree_method': 'gpu_hist',
              'predictor': 'gpu_predictor'}
    num_round = 10
    xgb_model = xgb.train(params, dtrain, num_boost_round=num_round,
                          evals=[(dtrain, 'train')])
    tl_model = treelite.Model.from_xgboost(xgb_model)

    # Insert NaN randomly into X
    X_test = X.copy()
    n_nan = int(np.floor(X.size * 0.1))
    rng = np.random.default_rng(seed=0)
    index_nan = rng.choice(X.size, size=n_nan, replace=False)
    X_test.ravel()[index_nan] = np.nan

    explainer = TreeExplainer(model=tl_model)
    out = explainer.shap_values(X_test)

    ref_explainer = shap.explainers.Tree(model=xgb_model)
    correct_out = ref_explainer.shap_values(X_test)
    np.testing.assert_almost_equal(out, correct_out, decimal=5)
    np.testing.assert_almost_equal(explainer.expected_value,
                                   ref_explainer.expected_value, decimal=5)


@pytest.mark.parametrize('objective,n_classes',
                         [('binary:logistic', 2),
                          ('binary:hinge', 2),
                          ('binary:logitraw', 2),
                          ('count:poisson', 4),
                          ('rank:pairwise', 5),
                          ('rank:ndcg', 5),
                          ('rank:map', 5),
                          ('multi:softmax', 5),
                          ('multi:softprob', 5)],
                         ids=['binary:logistic', 'binary:hinge',
                              'binary:logitraw', 'count:poisson',
                              'rank:pairwise', 'rank:ndcg', 'rank:map',
                              'multi:softmax', 'multi:softprob'])
@pytest.mark.skipif(not has_xgboost(), reason="need to install xgboost")
@pytest.mark.skipif(not has_shap(), reason="need to install shap")
@pytest.mark.skipif(not has_sklearn(), reason="need to install scikit-learn")
def test_xgb_classifier(objective, n_classes):
    n_samples = 100
    X, y = make_classification(n_samples=n_samples, n_features=8,
                               n_informative=8, n_redundant=0, n_repeated=0,
                               n_classes=n_classes, random_state=2021)
    X, y = X.astype(np.float32), y.astype(np.float32)
    num_round = 10
    dtrain = xgb.DMatrix(X, label=y)
    params = {'objective': objective, 'base_score': 0.5, 'seed': 0,
              'max_depth': 6, 'tree_method': 'gpu_hist',
              'predictor': 'gpu_predictor'}
    if objective.startswith('rank:'):
        dtrain.set_group([10] * 10)
    if n_classes > 2 and objective.startswith('multi:'):
        params['num_class'] = n_classes
    xgb_model = xgb.train(params, dtrain=dtrain, num_boost_round=num_round)

    # Insert NaN randomly into X
    X_test = X.copy()
    n_nan = int(np.floor(X.size * 0.1))
    rng = np.random.default_rng(seed=0)
    index_nan = rng.choice(X.size, size=n_nan, replace=False)
    X_test.ravel()[index_nan] = np.nan

    explainer = TreeExplainer(model=xgb_model)
    out = explainer.shap_values(X_test)

    ref_explainer = shap.explainers.Tree(model=xgb_model)
    correct_out = ref_explainer.shap_values(X_test)
    np.testing.assert_almost_equal(out, correct_out, decimal=5)
    np.testing.assert_almost_equal(explainer.expected_value,
                                   ref_explainer.expected_value, decimal=5)


def test_degenerate_cases():
    n_samples = 100
    cuml_model = curfr(max_features=1.0, max_samples=0.1, n_bins=128,
                       min_samples_leaf=2, random_state=123,
                       n_streams=1, n_estimators=10, max_leaves=-1,
                       max_depth=16, accuracy_metric="mse")
    # Attempt to import un-fitted model
    with pytest.raises(NotFittedError):
        TreeExplainer(model=cuml_model)

    # Depth 0 trees
    rng = np.random.default_rng(seed=0)
    X = rng.standard_normal(size=(n_samples, 8), dtype=np.float32)
    y = np.ones(shape=(n_samples,), dtype=np.float32)
    cuml_model.fit(X, y)
    explainer = TreeExplainer(model=cuml_model)
    out = explainer.shap_values(X)
    # Since the output is always 1.0 no matter the input, SHAP values for all
    # features are zero, as feature values don't have any effect on the output.
    # The bias (expected_value) is 1.0.
    assert np.all(out == 0)
    assert explainer.expected_value == 1.0


@pytest.mark.parametrize('input_type', ['numpy', 'cupy', 'cudf'])
@pytest.mark.skipif(not has_sklearn(), reason="need to install scikit-learn")
def test_cuml_rf_regressor(input_type):
    n_samples = 100
    X, y = make_regression(n_samples=n_samples, n_features=8, n_informative=8,
                           n_targets=1, random_state=2021)
    X, y = X.astype(np.float32), y.astype(np.float32)
    if input_type == 'cupy':
        X, y = cp.array(X), cp.array(y)
    elif input_type == 'cudf':
        X, y = cudf.DataFrame(X), cudf.Series(y)
    cuml_model = curfr(max_features=1.0, max_samples=0.1, n_bins=128,
                       min_samples_leaf=2, random_state=123,
                       n_streams=1, n_estimators=10, max_leaves=-1,
                       max_depth=16, accuracy_metric="mse")
    cuml_model.fit(X, y)
    pred = cuml_model.predict(X)

    explainer = TreeExplainer(model=cuml_model)
    out = explainer.shap_values(X)
    if input_type == 'cupy':
        pred = pred.get()
        out = out.get()
        expected_value = explainer.expected_value.get()
    elif input_type == 'cudf':
        pred = pred.to_numpy()
        out = out.get()
        expected_value = explainer.expected_value.get()
    else:
        expected_value = explainer.expected_value
    # SHAP values should add up to predicted score
    shap_sum = np.sum(out, axis=1) + expected_value
    np.testing.assert_almost_equal(shap_sum, pred, decimal=4)


@pytest.mark.parametrize('input_type', ['numpy', 'cupy', 'cudf'])
@pytest.mark.parametrize('n_classes', [2, 5])
@pytest.mark.skipif(not has_sklearn(), reason="need to install scikit-learn")
def test_cuml_rf_classifier(n_classes, input_type):
    n_samples = 100
    X, y = make_classification(n_samples=n_samples, n_features=8,
                               n_informative=8, n_redundant=0, n_repeated=0,
                               n_classes=n_classes, random_state=2021)
    X, y = X.astype(np.float32), y.astype(np.float32)
    if input_type == 'cupy':
        X, y = cp.array(X), cp.array(y)
    elif input_type == 'cudf':
        X, y = cudf.DataFrame(X), cudf.Series(y)
    cuml_model = curfc(max_features=1.0, max_samples=0.1, n_bins=128,
                       min_samples_leaf=2, random_state=123,
                       n_streams=1, n_estimators=10, max_leaves=-1,
                       max_depth=16, accuracy_metric="mse")
    cuml_model.fit(X, y)
    pred = cuml_model.predict_proba(X)

    explainer = TreeExplainer(model=cuml_model)
    out = explainer.shap_values(X)
    if input_type == 'cupy':
        pred = pred.get()
        out = out.get()
        expected_value = explainer.expected_value.get()
    elif input_type == 'cudf':
        pred = pred.to_numpy()
        out = out.get()
        expected_value = explainer.expected_value.get()
    else:
        expected_value = explainer.expected_value
    # SHAP values should add up to predicted score
    expected_value = expected_value.reshape(-1, 1)
    shap_sum = np.sum(out, axis=2) + np.tile(expected_value, (1, n_samples))
    pred = np.transpose(pred, (1, 0))
    np.testing.assert_almost_equal(shap_sum, pred, decimal=4)


@pytest.mark.skipif(not has_shap(), reason="need to install shap")
@pytest.mark.skipif(not has_sklearn(), reason="need to install scikit-learn")
def test_sklearn_rf_regressor():
    n_samples = 100
    X, y = make_regression(n_samples=n_samples, n_features=8, n_informative=8,
                           n_targets=1, random_state=2021)
    X, y = X.astype(np.float32), y.astype(np.float32)
    skl_model = sklrfr(max_features=1.0, max_samples=0.1,
                       min_samples_leaf=2, random_state=123,
                       n_estimators=10, max_depth=16)
    skl_model.fit(X, y)

    explainer = TreeExplainer(model=skl_model)
    out = explainer.shap_values(X)

    ref_explainer = shap.explainers.Tree(model=skl_model)
    correct_out = ref_explainer.shap_values(X)
    np.testing.assert_almost_equal(out, correct_out, decimal=5)
    np.testing.assert_almost_equal(explainer.expected_value,
                                   ref_explainer.expected_value, decimal=5)


@pytest.mark.parametrize('n_classes', [2, 3, 5])
@pytest.mark.skipif(not has_shap(), reason="need to install shap")
@pytest.mark.skipif(not has_sklearn(), reason="need to install scikit-learn")
def test_sklearn_rf_classifier(n_classes):
    n_samples = 100
    X, y = make_classification(n_samples=n_samples, n_features=8,
                               n_informative=8, n_redundant=0, n_repeated=0,
                               n_classes=n_classes, random_state=2021)
    X, y = X.astype(np.float32), y.astype(np.float32)
    skl_model = sklrfc(max_features=1.0, max_samples=0.1,
                       min_samples_leaf=2, random_state=123,
                       n_estimators=10, max_depth=16)
    skl_model.fit(X, y)

    explainer = TreeExplainer(model=skl_model)
    out = explainer.shap_values(X)

    ref_explainer = shap.explainers.Tree(model=skl_model)
    correct_out = np.array(ref_explainer.shap_values(X))
    expected_value = ref_explainer.expected_value
    if n_classes == 2:
        correct_out = correct_out[1, :, :]
        expected_value = expected_value[1:]
    np.testing.assert_almost_equal(out, correct_out, decimal=5)
    np.testing.assert_almost_equal(explainer.expected_value,
                                   expected_value, decimal=5)


@pytest.mark.skipif(not has_xgboost(), reason="need to install xgboost")
def test_xgb_toy_categorical():
    X = pd.DataFrame({'dummy': np.zeros(5, dtype=np.float32),
                      'x': np.array([0, 1, 2, 3, 4], dtype=np.int32)})
    y = np.array([0, 0, 1, 1, 1], dtype=np.float32)
    X['x'] = X['x'].astype("category")
    dtrain = xgb.DMatrix(X, y, enable_categorical=True)
    params = {"tree_method": "gpu_hist", "eval_metric": "error",
              "objective": "binary:logistic", "max_depth": 2,
              "min_child_weight": 0, "lambda": 0}
    xgb_model = xgb.train(params, dtrain, num_boost_round=1,
                          evals=[(dtrain, 'train')])
    explainer = TreeExplainer(model=xgb_model)
    out = explainer.shap_values(X)

    ref_out = xgb_model.predict(dtrain, pred_contribs=True)
    np.testing.assert_almost_equal(out, ref_out[:, :-1], decimal=5)
    np.testing.assert_almost_equal(explainer.expected_value, ref_out[0, -1],
                                   decimal=5)


@pytest.mark.parametrize('n_classes', [2, 3])
@pytest.mark.skipif(not has_xgboost(), reason="need to install xgboost")
@pytest.mark.skipif(not has_sklearn(), reason="need to install scikit-learn")
def test_xgb_classifier_with_categorical(n_classes):
    n_samples = 100
    n_features = 8
    X, y = make_classification_with_categorical(
        n_samples=n_samples, n_features=n_features, n_categorical=4,
        n_informative=n_features, n_redundant=0, n_repeated=0,
        n_classes=n_classes, random_state=2022)

    dtrain = xgb.DMatrix(X, y, enable_categorical=True)
    params = {"tree_method": "gpu_hist", "max_depth": 6,
              "base_score": 0.5, "seed": 0, "predictor": "gpu_predictor"}
    if n_classes == 2:
        params["objective"] = "binary:logistic"
        params["eval_metric"] = "logloss"
    else:
        params["objective"] = "multi:softprob"
        params["eval_metric"] = "mlogloss"
        params["num_class"] = n_classes
    xgb_model = xgb.train(params, dtrain, num_boost_round=10,
                          evals=[(dtrain, 'train')])
    assert count_categorical_split(treelite.Model.from_xgboost(xgb_model)) > 0

    # Insert NaN randomly into X
    X_test = X.values.copy()
    n_nan = int(np.floor(X.size * 0.1))
    rng = np.random.default_rng(seed=0)
    index_nan = rng.choice(X.size, size=n_nan, replace=False)
    X_test.ravel()[index_nan] = np.nan

    explainer = TreeExplainer(model=xgb_model)
    out = explainer.shap_values(X_test)

    dtest = xgb.DMatrix(X_test)
    ref_out = xgb_model.predict(dtest, pred_contribs=True,
                                validate_features=False)
    if n_classes == 2:
        ref_out, ref_expected_value = ref_out[:, :-1], ref_out[0, -1]
    else:
        ref_out = ref_out.transpose((1, 0, 2))
        ref_out, ref_expected_value = ref_out[:, :, :-1], ref_out[:, 0, -1]
    np.testing.assert_almost_equal(out, ref_out, decimal=5)
    np.testing.assert_almost_equal(explainer.expected_value,
                                   ref_expected_value, decimal=5)


@pytest.mark.skipif(not has_xgboost(), reason="need to install xgboost")
@pytest.mark.skipif(not has_sklearn(), reason="need to install scikit-learn")
def test_xgb_regressor_with_categorical():
    n_samples = 100
    n_features = 8
    X, y = make_regression_with_categorical(
        n_samples=n_samples, n_features=n_features, n_categorical=4,
        n_informative=n_features, random_state=2022)

    dtrain = xgb.DMatrix(X, y, enable_categorical=True)
    params = {"tree_method": "gpu_hist", "max_depth": 6,
              "base_score": 0.5, "seed": 0, "predictor": "gpu_predictor",
              "objective": "reg:squarederror", "eval_metric": "rmse"}
    xgb_model = xgb.train(params, dtrain, num_boost_round=10,
                          evals=[(dtrain, 'train')])
    assert count_categorical_split(treelite.Model.from_xgboost(xgb_model)) > 0

    explainer = TreeExplainer(model=xgb_model)
    out = explainer.shap_values(X)

    ref_out = xgb_model.predict(dtrain, pred_contribs=True)
    ref_out, ref_expected_value = ref_out[:, :-1], ref_out[0, -1]
    np.testing.assert_almost_equal(out, ref_out, decimal=5)
    np.testing.assert_almost_equal(explainer.expected_value,
                                   ref_expected_value, decimal=5)


@pytest.mark.skipif(not has_lightgbm(), reason="need to install lightgbm")
@pytest.mark.skipif(not has_sklearn(), reason="need to install scikit-learn")
@pytest.mark.skipif(not has_shap(), reason="need to install shap")
def test_lightgbm_regressor_with_categorical():
    n_samples = 100
    n_features = 8
    n_categorical = 8
    X, y = make_regression_with_categorical(
        n_samples=n_samples, n_features=n_features,
        n_categorical=n_categorical, n_informative=n_features,
        random_state=2022)

    dtrain = lgb.Dataset(X, label=y, categorical_feature=range(n_categorical))
    params = {"num_leaves": 64, "seed": 0, "objective": "regression",
              "metric": "rmse", "min_data_per_group": 1}
    lgb_model = lgb.train(params, dtrain, num_boost_round=10,
                          valid_sets=[dtrain], valid_names=['train'])
    assert count_categorical_split(
        treelite.Model.from_lightgbm(lgb_model)) > 0

    explainer = TreeExplainer(model=lgb_model)
    out = explainer.shap_values(X)

    ref_explainer = shap.explainers.Tree(model=lgb_model)
    ref_out = ref_explainer.shap_values(X)
    np.testing.assert_almost_equal(out, ref_out, decimal=5)
    np.testing.assert_almost_equal(explainer.expected_value,
                                   ref_explainer.expected_value, decimal=5)


@pytest.mark.parametrize('n_classes', [2, 3])
@pytest.mark.skipif(not has_lightgbm(), reason="need to install lightgbm")
@pytest.mark.skipif(not has_sklearn(), reason="need to install scikit-learn")
@pytest.mark.skipif(not has_shap(), reason="need to install shap")
def test_lightgbm_classifier_with_categorical(n_classes):
    n_samples = 100
    n_features = 8
    n_categorical = 8
    X, y = make_classification_with_categorical(
        n_samples=n_samples, n_features=n_features,
        n_categorical=n_categorical, n_informative=n_features,
        n_redundant=0, n_repeated=0, n_classes=n_classes,
        random_state=2022)

    dtrain = lgb.Dataset(X, label=y, categorical_feature=range(n_categorical))
    params = {"num_leaves": 64, "seed": 0, "min_data_per_group": 1}
    if n_classes == 2:
        params["objective"] = "binary"
        params["metric"] = "binary_logloss"
    else:
        params["objective"] = "multiclass"
        params["metric"] = "multi_logloss"
        params["num_class"] = n_classes
    lgb_model = lgb.train(params, dtrain, num_boost_round=10,
                          valid_sets=[dtrain], valid_names=['train'])
    assert count_categorical_split(
        treelite.Model.from_lightgbm(lgb_model)) > 0

    # Insert NaN randomly into X
    X_test = X.values.copy()
    n_nan = int(np.floor(X.size * 0.1))
    rng = np.random.default_rng(seed=0)
    index_nan = rng.choice(X.size, size=n_nan, replace=False)
    X_test.ravel()[index_nan] = np.nan

    explainer = TreeExplainer(model=lgb_model)
    out = explainer.shap_values(X_test)

    ref_explainer = shap.explainers.Tree(model=lgb_model)
    ref_out = np.array(ref_explainer.shap_values(X_test))
    if n_classes == 2:
        ref_out = ref_out[1, :, :]
        ref_expected_value = ref_explainer.expected_value[1]
    else:
        ref_expected_value = ref_explainer.expected_value
    np.testing.assert_almost_equal(out, ref_out, decimal=5)
    np.testing.assert_almost_equal(explainer.expected_value,
                                   ref_expected_value, decimal=5)


def learn_model(
        draw, X, y, task, learner, n_estimators, n_targets):
    # for lgbm or xgb return the booster or sklearn object?
    use_sklearn_estimator = draw(st.booleans())
    if learner == 'xgb':
        assume(has_xgboost())
        if task == 'regression':
            objective = draw(st.sampled_from(['reg:squarederror',
                                              'reg:pseudohubererror']))
            model = xgb.XGBRegressor(
                n_estimators=n_estimators, tree_method='gpu_hist',
                objective=objective, enable_categorical=True, verbosity=0).fit(
                X, y)
        elif task == 'classification':
            valid_objectives = ['binary:logistic', 'binary:hinge',
                                'binary:logitraw', 'count:poisson', ]
            if n_targets > 2:
                valid_objectives += ['rank:pairwise', 'rank:ndcg', 'rank:map',
                                     'multi:softmax', 'multi:softprob']

            objective = draw(st.sampled_from(valid_objectives))
            model = xgb.XGBClassifier(
                n_estimators=n_estimators, tree_method='gpu_hist',
                objective=objective, enable_categorical=True, verbosity=0).fit(
                X, y)
        pred = model.predict(X, output_margin=True)
        if not use_sklearn_estimator:
            model = model.get_booster()
        return model, pred
    elif learner == 'rf':
        predict_model = 'GPU 'if y.dtype == np.float32 else 'CPU'
        if task == 'regression':
            model = cuml.ensemble.RandomForestRegressor(
                n_estimators=n_estimators)
            model.fit(X, y)
            pred = model.predict(X, predict_model=predict_model)
        elif task == 'classification':
            model = cuml.ensemble.RandomForestClassifier(
                n_estimators=n_estimators)
            model.fit(X, y)
            pred = model.predict_proba(X)
        return model, pred
    elif learner == 'skl_rf':
        assume(has_sklearn())
        if task == 'regression':
            model = sklrfr(
                n_estimators=n_estimators)
            model.fit(X, y)
            pred = model.predict(X)
        elif task == 'classification':
            model = sklrfc(
                n_estimators=n_estimators)
            model.fit(X, y)
            pred = model.predict_proba(X)
        return model, pred
    elif learner == 'lgbm':
        assume(has_lightgbm())
        if task == 'regression':
            model = lgb.LGBMRegressor(
                n_estimators=n_estimators).fit(X, y)
        elif task == 'classification':
            model = lgb.LGBMClassifier(
                n_estimators=n_estimators).fit(X, y)
        pred = model.predict(X, raw_score=True)
        if not use_sklearn_estimator:
            model = model.booster_
        return model, pred


@st.composite
def shap_strategy(draw):
    task = draw(st.sampled_from(['regression', 'classification']))

    n_estimators = draw(st.integers(1, 16))
    n_samples = draw(st.integers(2, 100))
    n_features = draw(st.integers(2, 100))
    learner = draw(st.sampled_from(['xgb', 'rf', 'skl_rf', 'lgbm']))
    supports_categorical = learner in ['xgb', 'lgbm']
    supports_nan = learner in ['xgb', 'lgbm']
    if task == 'classification':
        n_targets = draw(st.integers(2, 5))
    else:
        n_targets = 1
    n_targets = min(n_targets, n_features)
    n_targets = min(n_targets, n_samples)

    has_categoricals = draw(st.booleans()) and supports_categorical
    dtype = draw(st.sampled_from([np.float32, np.float64]))
    if has_categoricals:
        n_categorical = draw(st.integers(1, n_features))
    else:
        n_categorical = 0

    has_nan = not has_categoricals and supports_nan

    # Filter issues and invalid examples here
    if task == 'classification' and learner == 'rf':
        # No way to predict_proba with RandomForestClassifier
        # trained on 64-bit data
        # https://github.com/rapidsai/cuml/issues/4663
        assume(dtype == np.float32)
    if task == 'regression' and learner == 'skl_rf':
        # multi-output regression not working
        # https://github.com/dmlc/treelite/issues/375
        assume(n_targets == 1)

    # treelite considers a binary classification model to have
    # n_classes=1, which produces an unexpected output shape
    # in the shap values
    if task == 'classification' and learner == 'skl_rf':
        assume(n_targets > 2)

    # ensure we get some variation in test datasets
    dataset_seed = draw(st.integers(1, 5))
    if task == 'classification':
        X, y = make_classification_with_categorical(
            n_samples=n_samples, n_features=n_features,
            n_categorical=n_categorical, n_informative=n_features,
            n_redundant=0, n_repeated=0, random_state=dataset_seed,
            n_classes=n_targets, numeric_dtype=dtype)
    else:
        X, y = make_regression_with_categorical(
            n_samples=n_samples, n_features=n_features,
            n_categorical=n_categorical, n_informative=n_features,
            random_state=dataset_seed, numeric_dtype=dtype,
            n_targets=n_targets)

    if has_nan:
        # set about half the first column to nan
        X.iloc[np.random.randint(0, n_samples, n_samples//2), 0] = np.nan

    assert len(X.select_dtypes(include='category').columns) == n_categorical

    model, preds = learn_model(
        draw, X, y, task, learner, n_estimators, n_targets)

    # convert any DataFrame categorical columns to numeric
    return X.astype(dtype), y.astype(dtype), model, preds


def check_efficiency(expected_value, pred, shap_values):
    # shap values add up to prediction
    if len(shap_values.shape) <= 2:
        assert np.allclose(np.sum(shap_values, axis=-1) +
                           expected_value, pred, 1e-3, 1e-3)
    else:
        n_targets = shap_values.shape[0]
        for i in range(n_targets):
            assert np.allclose(
                np.sum(shap_values[i],
                       axis=-1) + expected_value[i],
                pred[:, i],
                1e-3, 1e-3)


def check_efficiency_interactions(expected_value, pred, shap_values):
    # shap values add up to prediction
    if len(shap_values.shape) <= 3:
        assert np.allclose(np.sum(shap_values, axis=(-2, -1)) +
                           expected_value, pred, 1e-3, 1e-3)
    else:
        n_targets = shap_values.shape[0]
        for i in range(n_targets):
            assert np.allclose(
                np.sum(shap_values[i],
                       axis=(-2, -1)) + expected_value[i],
                pred[:, i],
                1e-3, 1e-3)


# Generating input data/models can be time consuming and triggers
# hypothesis HealthCheck
@settings(deadline=None, max_examples=20,
          suppress_health_check=[HealthCheck.too_slow,
                                 HealthCheck.data_too_large])
@given(shap_strategy(),
       st.sampled_from(["shapley-interactions", "shapley-taylor"]))
def test_with_hypothesis(params, interactions_method):
    X, y, model, preds = params
    explainer = TreeExplainer(model=model)
    shap_values = explainer.shap_values(X)
    shap_interactions = explainer.shap_interaction_values(
        X, method=interactions_method)
    check_efficiency(explainer.expected_value, preds, shap_values)
    check_efficiency_interactions(
        explainer.expected_value, preds, shap_interactions)

    # Interventional
    explainer = TreeExplainer(model=model, data=X.sample(
        n=15, replace=True, random_state=0))
    interventional_shap_values = explainer.shap_values(X)
    check_efficiency(explainer.expected_value, preds,
                     interventional_shap_values)


def test_wrong_inputs():
    X = np.array([[0.0, 2.0], [1.0, 0.5]])
    y = np.array([0, 1])
    model = cuml.ensemble.RandomForestRegressor().fit(X, y)

    # background/X different dtype
    with pytest.raises(ValueError, match="Expected background data"
                       " to have the same dtype"):
        explainer = TreeExplainer(model=model, data=X.astype(np.float32))
        explainer.shap_values(X)

    # background/X different number columns
    with pytest.raises(RuntimeError):
        explainer = TreeExplainer(model=model, data=X[:, 0:1])
        explainer.shap_values(X)

    with pytest.raises(ValueError, match="Interventional algorithm not"
                       " supported for interactions. Please"
                       " specify data as None in constructor."):
        explainer = TreeExplainer(model=model, data=X.astype(np.float32))
        explainer.shap_interaction_values(X)

    with pytest.raises(ValueError, match="Unknown interactions method."):
        explainer = TreeExplainer(model=model)
        explainer.shap_interaction_values(X, method='asdasd')


def test_different_algorithms_different_output():
    # ensure different algorithms are actually being called
    rng = np.random.RandomState(3)
    X = rng.normal(size=(100, 10))
    y = rng.normal(size=100)
    model = cuml.ensemble.RandomForestRegressor().fit(X, y)
    interventional_explainer = TreeExplainer(model=model, data=X)
    explainer = TreeExplainer(model=model)
    assert not np.all(explainer.shap_values(
        X) == interventional_explainer.shap_values(X))
    assert not np.all(
        explainer.shap_interaction_values(X, method="shapley-interactions") ==
        explainer.shap_interaction_values(X, method="shapley-taylor"))


@settings(deadline=None)
@given(st.sampled_from(['numpy', 'cupy', 'cudf', 'pandas']))
def test_input_types(input_type):
    # simple test to not crash on different input data-frames
    X = np.array([[0.0, 2.0], [1.0, 0.5]])
    y = np.array([0, 1])
    X, y = as_type(input_type, X, y)
    model = cuml.ensemble.RandomForestRegressor().fit(X, y)
    explainer = TreeExplainer(model=model)
    explainer.shap_values(X)
