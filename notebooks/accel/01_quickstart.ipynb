{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470981d2",
   "metadata": {},
   "source": [
    "# cuML.accel Quickstart\n",
    "\n",
    "`cuml.accel` provides alternative, highly-optimized implementations for specific algorithms by leveraging other specialized GPU libraries.\n",
    "\n",
    "This notebook demonstrates how to use `cuml.accel` and compares its performance against the standard `cuml` and `scikit-learn` (CPU) implementations for the K-Nearest Neighbors algorithm.\n",
    "\n",
    "Useful links:\n",
    "- cuML documentation: https://docs.rapids.ai/api/cuml/stable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef09197",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "To run this notebook, you need a machine with an NVIDIA GPU and a proper RAPIDS environment. The recommended way to install RAPIDS is with Conda.\n",
    "\n",
    "Please visit the [RAPIDS Release Selector](https://rapids.ai/start.html#get-rapids) to get the specific `conda install` command for your system.\n",
    "\n",
    "An example command might look like this (do not run, use the official selector):\n",
    "`conda create -n rapids-25.08 -c rapidsai -c conda-forge -c nvidia cuml cudf cupy python=3.10 cuda-version=12.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f49e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "\n",
    "# Import the models we will compare\n",
    "from sklearn.neighbors import NearestNeighbors as skNearestNeighbors\n",
    "from cuml.neighbors import NearestNeighbors as cumlNearestNeighbors\n",
    "\n",
    "from cuml.datasets import make_blobs\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b401e7",
   "metadata": {},
   "source": [
    "## Generate Data\n",
    "\n",
    "We will generate a random dataset of blobs to test the algorithm's performance. The data is created directly on the GPU using `cuml.datasets.make_blobs` and a copy is transferred to the CPU for the scikit-learn comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "654358c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generated successfully:\n",
      "Shape of the data: (50000, 50)\n",
      "X_gpu type: <class 'cupy.ndarray'>\n",
      "X_cpu type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Define parameters for the experiment\n",
    "n_samples = 50000\n",
    "n_features = 50\n",
    "n_neighbors = 10\n",
    "\n",
    "# Generate the data directly on the GPU using cuML's make_blobs\n",
    "X_gpu, _ = make_blobs(n_samples=n_samples, \n",
    "                      n_features=n_features, \n",
    "                      random_state=42)\n",
    "\n",
    "# Create a copy on the CPU (as a NumPy array) for the scikit-learn comparison\n",
    "X_cpu = X_gpu.get()\n",
    "\n",
    "print(\"Data generated successfully:\")\n",
    "print(f\"Shape of the data: {X_gpu.shape}\")\n",
    "print(f\"X_gpu type: {type(X_gpu)}\")\n",
    "print(f\"X_cpu type: {type(X_cpu)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f418b2a8",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "### 1. scikit-learn (CPU Baseline)\n",
    "\n",
    "First, we'll run the standard scikit-learn `NearestNeighbors` implementation on the CPU using the NumPy data. This will serve as our performance baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7943bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn (CPU) time: 1.0724 seconds\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Instantiate the scikit-learn model\n",
    "model_sk = skNearestNeighbors(n_neighbors=n_neighbors)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model and find the neighbors\n",
    "# Note: We use the CPU data (X_cpu)\n",
    "model_sk.fit(X_cpu)\n",
    "distances, indices = model_sk.kneighbors(X_cpu)\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the duration\n",
    "time_sk = end_time - start_time\n",
    "print(f\"Scikit-learn (CPU) time: {time_sk:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5255425a",
   "metadata": {},
   "source": [
    "### 2. Standard cuML (GPU)\n",
    "\n",
    "Now, we'll perform the same task using cuML on the GPU. We'll specify `algorithm='brute'` to ensure an apples-to-apples comparison with scikit-learn, which also uses a brute-force method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64caecf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard cuML (GPU, Brute) time: 0.2801 seconds\n",
      "Speedup vs CPU: 3.83x\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Instantiate the standard cuML model\n",
    "model_cuml = cumlNearestNeighbors(n_neighbors=n_neighbors, algorithm='brute')\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model and find the neighbors\n",
    "# Note: We use the GPU data (X_gpu)\n",
    "model_cuml.fit(X_gpu)\n",
    "distances_cuml, indices_cuml = model_cuml.kneighbors(X_gpu)\n",
    "\n",
    "# IMPORTANT: Synchronize the GPU to get an accurate timing\n",
    "cp.cuda.runtime.deviceSynchronize()\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the duration\n",
    "time_cuml = end_time - start_time\n",
    "print(f\"Standard cuML (GPU, Brute) time: {time_cuml:.4f} seconds\")\n",
    "print(f\"Speedup vs CPU: {time_sk / time_cuml:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a33b44e",
   "metadata": {},
   "source": [
    "### 3. Accelerated cuML (GPU with IVF-Flat)\n",
    "\n",
    "Finally, we'll test the even more optimized version. The `ivf-flat` algorithm is not brute-force. It works by first building a smart index that partitions the data. When searching for neighbors, it only needs to check a few partitions instead of the entire dataset, making it much faster for large `n_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4be96b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerated cuML (GPU, IVF-Flat) time: 0.2235 seconds\n",
      "Speedup vs CPU: 4.80x\n",
      "Speedup vs Standard GPU: 1.25x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enzovelo/miniconda3/envs/rapids-25.08/lib/python3.13/site-packages/cuml/internals/api_decorators.py:211: UserWarning: \n",
      "Warning: Approximate Nearest Neighbor methods might be unstable in this version of cuML. This is due to a known issue in the FAISS release that this cuML version is linked to. (see cuML issue #4020)\n",
      "  ret = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Instantiate the accelerated cuML model using the IVF-Flat index\n",
    "model_accel = cumlNearestNeighbors(n_neighbors=n_neighbors, algorithm='ivfflat')\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model and find the neighbors\n",
    "model_accel.fit(X_gpu)\n",
    "distances_accel, indices_accel = model_accel.kneighbors(X_gpu)\n",
    "\n",
    "# Synchronize the GPU\n",
    "cp.cuda.runtime.deviceSynchronize()\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the duration\n",
    "time_accel = end_time - start_time\n",
    "print(f\"Accelerated cuML (GPU, IVF-Flat) time: {time_accel:.4f} seconds\")\n",
    "print(f\"Speedup vs CPU: {time_sk / time_accel:.2f}x\")\n",
    "print(f\"Speedup vs Standard GPU: {time_cuml / time_accel:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f896b4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Let's summarize the results from our three tests. As we can see, moving from CPU to GPU provides a significant speedup, and choosing a specialized, index-based algorithm like `ivf-flat` can boost performance even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46d7d6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance Summary ---\n",
      "1. scikit-learn (CPU):         1.0724 seconds\n",
      "2. cuml (GPU, Brute):          0.2801 seconds (Speedup: 3.83x)\n",
      "3. cuml (GPU, IVF-Flat):       0.2235 seconds (Speedup: 4.80x)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(\"--- Performance Summary ---\")\n",
    "print(f\"1. scikit-learn (CPU):         {time_sk:.4f} seconds\")\n",
    "print(f\"2. cuml (GPU, Brute):          {time_cuml:.4f} seconds (Speedup: {time_sk / time_cuml:.2f}x)\")\n",
    "print(f\"3. cuml (GPU, IVF-Flat):       {time_accel:.4f} seconds (Speedup: {time_sk / time_accel:.2f}x)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
