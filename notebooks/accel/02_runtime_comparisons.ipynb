{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45e57f28",
   "metadata": {},
   "source": [
    "# Runtime Comparisons: Scaling CPU vs. GPU\n",
    "\n",
    "This notebook provides an in-depth performance comparison between scikit-learn (CPU), `cuml` (GPU Brute-Force), and `cuml` with `ivfflat` (GPU Indexed).\n",
    "\n",
    "We will benchmark the `NearestNeighbors` algorithm across a range of dataset sizes (`n_samples`) and visualize the results to understand how each implementation scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the models\n",
    "from sklearn.neighbors import NearestNeighbors as skNearestNeighbors\n",
    "from cuml.neighbors import NearestNeighbors as cumlNearestNeighbors\n",
    "from cuml.datasets import make_blobs\n",
    "\n",
    "# Set a consistent plotting style\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d938184d",
   "metadata": {},
   "source": [
    "## 1. Benchmark Function\n",
    "\n",
    "To keep our code clean and avoid repetition, we'll define a single function to handle the data generation and timing for each model type and data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5536e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(model_type, n_samples, n_features, n_neighbors):\n",
    "    \"\"\"\n",
    "    Generates data and times a NearestNeighbors model run.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_type (str): 'sklearn', 'cuml_brute', or 'cuml_ivfflat'.\n",
    "    - n_samples (int): Number of samples to generate.\n",
    "    - n_features (int): Number of features per sample.\n",
    "    - n_neighbors (int): Number of neighbors to find.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Execution time in seconds.\n",
    "    \"\"\"\n",
    "    # 1. Generate Data\n",
    "    X_gpu, _ = make_blobs(n_samples=n_samples, \n",
    "                          n_features=n_features, \n",
    "                          random_state=42)\n",
    "    \n",
    "    # 2. Select Model and Data Source\n",
    "    if model_type == 'sklearn':\n",
    "        model = skNearestNeighbors(n_neighbors=n_neighbors)\n",
    "        X_data = X_gpu.get() # Transfer data to CPU\n",
    "    elif model_type == 'cuml_brute':\n",
    "        model = cumlNearestNeighbors(n_neighbors=n_neighbors, algorithm='brute')\n",
    "        X_data = X_gpu\n",
    "    elif model_type == 'cuml_ivfflat':\n",
    "        model = cumlNearestNeighbors(n_neighbors=n_neighbors, algorithm='ivfflat')\n",
    "        X_data = X_gpu\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type provided.\")\n",
    "\n",
    "    # 3. Time the Execution\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.fit(X_data)\n",
    "    distances, indices = model.kneighbors(X_data)\n",
    "    \n",
    "    # Synchronize only for GPU models to ensure computation is finished\n",
    "    if 'cuml' in model_type:\n",
    "        cp.cuda.runtime.deviceSynchronize()\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc5c60",
   "metadata": {},
   "source": [
    "## 2. Running the Benchmarks\n",
    "\n",
    "Now, we'll define the parameters for our experiment and loop through them, calling our benchmark function and storing the results. This may take a few minutes to run, especially the larger CPU tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb18d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sample sizes to test\n",
    "SAMPLES_LIST = [10_000, 50_000, 100_000, 250_000, 500_000]\n",
    "N_FEATURES = 50\n",
    "N_NEIGHBORS = 10\n",
    "\n",
    "# List of models to test\n",
    "MODEL_TYPES = ['sklearn', 'cuml_brute', 'cuml_ivfflat']\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Main benchmark loop\n",
    "print(\"Starting benchmarks...\")\n",
    "for n_samples in SAMPLES_LIST:\n",
    "    print(f\"\\nTesting with n_samples = {n_samples:,}...\")\n",
    "    times = {}\n",
    "    for model_type in MODEL_TYPES:\n",
    "        exec_time = benchmark_model(model_type, n_samples, N_FEATURES, N_NEIGHBORS)\n",
    "        times[model_type] = exec_time\n",
    "        print(f\"  - {model_type}: {exec_time:.4f} seconds\")\n",
    "    results[n_samples] = times\n",
    "\n",
    "# Convert the results to a Pandas DataFrame for easy plotting and display\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "print(\"\\n--- Results Table (in seconds) ---\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6df92f",
   "metadata": {},
   "source": [
    "## 3. Visualizing the Results\n",
    "\n",
    "A plot is the most effective way to see how each algorithm scales with the size of the data. We'll use a logarithmic scale on the y-axis to clearly visualize the performance of all three models, even though their runtimes differ by orders of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e274edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and axes for the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot the results for each model with distinct markers and styles\n",
    "ax.plot(results_df.index, results_df['sklearn'], marker='o', linestyle='--', label='Scikit-learn (CPU)')\n",
    "ax.plot(results_df.index, results_df['cuml_brute'], marker='s', linestyle='-', label='cuML Brute (GPU)')\n",
    "ax.plot(results_df.index, results_df['cuml_ivfflat'], marker='^', linestyle='-', label='cuML IVF-Flat (GPU)')\n",
    "\n",
    "# Configure the labels and title for clarity\n",
    "ax.set_xlabel(\"Number of Samples (n_samples)\")\n",
    "ax.set_ylabel(\"Execution Time (seconds) - Logarithmic Scale\")\n",
    "ax.set_title(\"Performance Scaling: CPU vs. GPU (NearestNeighbors)\")\n",
    "\n",
    "# Use a logarithmic scale for the Y-axis to compare orders of magnitude\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Add a legend and grid for readability\n",
    "ax.legend()\n",
    "ax.grid(True, which=\"both\", linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Show the final plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f60c915",
   "metadata": {},
   "source": [
    "## 4. Conclusion\n",
    "\n",
    "The graph clearly illustrates the scaling advantage of GPU-accelerated computing.\n",
    "\n",
    "- **GPU vs CPU**: The performance gap between `cuml` and `scikit-learn` widens dramatically as the dataset size increases, showcasing the power of GPU parallelism.\n",
    "- **Brute vs IVF-Flat**: For smaller datasets, the brute-force algorithm is competitive due to the overhead of building an index for IVF-Flat. However, as `n_samples` grows, the indexed `ivfflat` algorithm's superior scaling makes it the clear winner for large-scale problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
