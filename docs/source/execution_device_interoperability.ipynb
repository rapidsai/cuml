{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Execution device interoperability\n",
    "\n",
    "This notebook demonstrates the `CPU/GPU interoperability feature`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pickle\n",
    "import cuml\n",
    "from cuml.common.device_selection import DeviceType, using_device_type\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "from cuml.linear_model import LinearRegression\n",
    "from cuml.datasets import make_regression, make_blobs\n",
    "from cuml.model_selection import train_test_split\n",
    "\n",
    "X_blobs, y_blobs = make_blobs(n_samples=2000, n_features=20)\n",
    "X_train_blobs, X_test_blobs, y_train_blobs, y_test_blobs = train_test_split(X_blobs, y_blobs, test_size=0.2, shuffle=True)\n",
    "\n",
    "X_reg, y_reg = make_regression(n_samples=2000, n_features=20)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_tes_reg = train_test_split(X_reg, y_reg, test_size=0.2, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Don't have a GPU at disposal at the moment? You can work on prototyping and run estimators in CPU-mode."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "nn = NearestNeighbors()\n",
    "with using_device_type('cpu'):\n",
    "    nn.fit(X_train_blobs)\n",
    "    nearest_neighbors = nn.kneighbors(X_test_blobs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Willing to deploy a ML service on a CPU-only server? Do the compute intensive training on GPU and run the inferences on a cheaper CPU server.\n",
    "\n",
    "First, train the estimator on device and save it to disk."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "lin_reg = LinearRegression()\n",
    "with using_device_type('gpu'):\n",
    "    lin_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "pickle.dump(lin_reg, open(\"lin_reg.pkl\", \"wb\"))\n",
    "del lin_reg"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, on the server, recover the estimator and run the inference on host."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "recovered_lin_reg = pickle.load(open(\"lin_reg.pkl\", \"rb\"))\n",
    "with using_device_type('cpu'):\n",
    "    predictions = recovered_lin_reg.predict(X_test_reg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The GPU/device is the default execution platform :"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "initial_device_type = cuml.global_settings.device_type\n",
    "print('initial_device_type:', initial_device_type)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "initial_device_type: DeviceType.device\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Estimators trainings and inferences inside a `using_device_type` context will be executed according to the execution platform selected :"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for param in ['cpu', 'host', 'gpu', 'device']:\n",
    "    with using_device_type(param):\n",
    "        print('using_device_type({}):'.format(param), cuml.global_settings.device_type)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using_device_type(cpu): DeviceType.host\n",
      "using_device_type(host): DeviceType.host\n",
      "using_device_type(gpu): DeviceType.device\n",
      "using_device_type(device): DeviceType.device\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The execution platform can as well be set at the global level from the `cuml.global_settings.device_type` value."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "cuml.global_settings.device_type = DeviceType.host"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.15 64-bit ('all_cuda-115_arch-x86_64': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "interpreter": {
   "hash": "35840739db47a5016f18b089945bf3e154a2dca6d71cfb13687d370b69a146e3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}